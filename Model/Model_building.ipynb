{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84475731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ReLU\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn import BatchNorm1d, Linear, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b052c",
   "metadata": {},
   "source": [
    "# model for 1D SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249bb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text, extract_features=False):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        if extract_features:\n",
    "            return hidden.squeeze(0) # extract feature\n",
    "        hidden = hidden.squeeze(0)\n",
    "        dense_outputs = self.fc(hidden)\n",
    "        return dense_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3c91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedRNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, output_dim, num_layers=2, bidirectional=False, dropout_p=0.5):\n",
    "        super(AdvancedRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout_p, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text, extract_features=False):\n",
    "        embedded = self.embedding(text)\n",
    "        embedded = self.dropout(embedded)  \n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        \n",
    "        if extract_features:\n",
    "            if self.lstm.bidirectional:\n",
    "                hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "            else:\n",
    "                hidden = hidden.squeeze(0)\n",
    "            return hidden  \n",
    "\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden.squeeze(0)\n",
    "        \n",
    "        hidden = self.dropout(hidden) \n",
    "        dense_outputs = self.fc(hidden)\n",
    "        return dense_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe7013",
   "metadata": {},
   "source": [
    "# model for 2D graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a22e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNNnodes(torch.nn.Module):\n",
    "    def __init__(self, num_node_features,output_dim):\n",
    "        super(GCNNnodes, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.fc = nn.Linear(32, output_dim)\n",
    "    def forward(self, data, extract_features=False):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        if extract_features:\n",
    "            return x\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7258c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class EnhancedGCNNnodes(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, output_dim, dropout_rate=0.5):\n",
    "        super(EnhancedGCNNnodes, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.bn1 = BatchNorm1d(16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.bn2 = BatchNorm1d(32)\n",
    "        self.conv3 = GCNConv(32, 64)\n",
    "        self.bn3 = BatchNorm1d(64)\n",
    "        self.dropout = Dropout(p=dropout_rate)\n",
    "        self.fc1 = Linear(64, 32)\n",
    "        self.fc2 = Linear(32, output_dim)\n",
    "\n",
    "    def forward(self, data, extract_features=False):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
    "        x = F.relu(self.bn3(self.conv3(x, edge_index)))\n",
    "        x = global_mean_pool(x, batch) \n",
    "\n",
    "        if extract_features:\n",
    "            return x  \n",
    "        x = self.dropout(x)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc05ead",
   "metadata": {},
   "source": [
    "# model for 3D graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7fd6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "class GraphNN3D(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, output_dim):\n",
    "        super(GraphNN3D, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, 128)\n",
    "        self.fc1 = torch.nn.Linear(128 + num_edge_features, 64)  # Combine node and edge features\n",
    "        self.fc2 = torch.nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, data, extract_features=False):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # Graph convolution layers\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)  # Aggregate features from all nodes\n",
    "\n",
    "        # Combine with edge features\n",
    "        # Here we assume edge_attr is aggregated beforehand or represent global graph properties\n",
    "        \n",
    "        edge_feature_aggregated = edge_attr.mean(dim=0)  # Example of simple aggregation\n",
    "        x = torch.cat([x, edge_feature_aggregated.unsqueeze(0).repeat(x.size(0), 1)], dim=1)\n",
    "        \n",
    "        if extract_features:\n",
    "            # Return the combined node and edge features\n",
    "            return x\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafbee42",
   "metadata": {},
   "source": [
    "# model for 3D voxelization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0983269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self, num_channels, output_dim):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=num_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=64 * 5 * 5 * 5, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=output_dim)\n",
    "\n",
    "    def forward(self, x, extract_features=False):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) \n",
    "        \n",
    "        if extract_features:\n",
    "            return x\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c5332",
   "metadata": {},
   "source": [
    "# model for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c8508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e88faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ComplexMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_dim, dropout_rate=0.5):\n",
    "        super(ComplexMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
    "        self.fc4 = nn.Linear(hidden_sizes[2], output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
