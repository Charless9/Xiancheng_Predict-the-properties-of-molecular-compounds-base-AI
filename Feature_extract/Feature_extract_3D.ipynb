{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9b004c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8dd1e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_file=\"../dataset/canonical_trainset.csv\"\n",
    "canonical_smiles_df=pd.read_csv(canonical_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0af529aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nbimporter\n",
    "\n",
    "project_root = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from datapreparation import Data_Processing_3D as nb3\n",
    "\n",
    "\n",
    "graph_data = nb3.preprocess_smiles_with_labels_3d(canonical_smiles_df[\"SMILES\"][:50].values, canonical_smiles_df[\"Label\"][:50].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b81c27",
   "metadata": {},
   "source": [
    "# Process voxels and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e876f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 20, 20, 20)\n",
      "(50,)\n",
      "torch.Size([50, 1, 20, 20, 20])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "voxels = np.array([item['voxels'] for item in graph_data])  # [num_samples, depth, height, width]\n",
    "labels = np.array([item['label'] for item in graph_data])  # [num_samples,]\n",
    "voxels = torch.tensor(voxels, dtype=torch.float).unsqueeze(1)  # [num_samples, 1, depth, height, width]\n",
    "labels = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ee9d6",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "519fa71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "voxels_train, voxels_test, labels_train, labels_test = train_test_split(voxels, labels, test_size=0.2, random_state=42)\n",
    "train_dataset = TensorDataset(voxels_train, labels_train)\n",
    "test_dataset = TensorDataset(voxels_test, labels_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284d847",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "398b8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, feature_extract=False):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        if feature_extract:\n",
    "            x = x.view(x.size(0), -1)  \n",
    "            x = F.relu(self.fc1(x))\n",
    "            return x\n",
    "        x = x.view(-1, 32 * 5 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55b2c6",
   "metadata": {},
   "source": [
    "# train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "134762e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.4690, Train Accuracy: 0.8500, Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Model saved at Epoch 1\n",
      "Epoch 2, Train Loss: 0.3851, Train Accuracy: 0.9500, Validation Loss: 0.0939, Validation Accuracy: 1.0000\n",
      "Epoch 3, Train Loss: 0.2184, Train Accuracy: 0.9500, Validation Loss: 0.0720, Validation Accuracy: 1.0000\n",
      "Epoch 4, Train Loss: 0.2126, Train Accuracy: 0.9500, Validation Loss: 0.0575, Validation Accuracy: 1.0000\n",
      "Epoch 5, Train Loss: 0.2073, Train Accuracy: 0.9500, Validation Loss: 0.0614, Validation Accuracy: 1.0000\n",
      "Epoch 6, Train Loss: 0.2248, Train Accuracy: 0.9500, Validation Loss: 0.0392, Validation Accuracy: 1.0000\n",
      "Epoch 7, Train Loss: 0.2192, Train Accuracy: 0.9500, Validation Loss: 0.0820, Validation Accuracy: 1.0000\n",
      "Epoch 8, Train Loss: 0.1925, Train Accuracy: 0.9500, Validation Loss: 0.0406, Validation Accuracy: 1.0000\n",
      "Epoch 9, Train Loss: 0.2096, Train Accuracy: 0.9500, Validation Loss: 0.0456, Validation Accuracy: 1.0000\n",
      "Epoch 10, Train Loss: 0.2169, Train Accuracy: 0.9500, Validation Loss: 0.0572, Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = Simple3DCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for voxels_batch, labels_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(voxels_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels_batch.size(0)\n",
    "        correct += (predicted == labels_batch).sum().item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for voxels_batch, labels_batch in test_loader:\n",
    "            outputs = model(voxels_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels_batch.size(0)\n",
    "            correct += (predicted == labels_batch).sum().item()\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_accuracy = validate(model, test_loader, criterion)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), 'best3_model.pth')\n",
    "        print(\"Model saved at Epoch\", epoch+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a635f52",
   "metadata": {},
   "source": [
    "# extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "176f37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_3d(model, loader):\n",
    "    model.eval()  \n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():  \n",
    "        for voxels, label in loader:\n",
    "            feature = model(voxels, feature_extract=True)\n",
    "            features.append(feature.cpu().numpy())\n",
    "            labels.append(label.cpu().numpy())\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e5b4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best3_model.pth'))\n",
    "all_loader = DataLoader(TensorDataset(voxels, labels), batch_size=4, shuffle=False)\n",
    "all_features, all_labels = extract_features_3d(model, all_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5d5929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 128)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(all_features.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d895e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
