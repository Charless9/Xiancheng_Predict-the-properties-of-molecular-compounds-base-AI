{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dba9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from math import sqrt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import nbimporter\n",
    "\n",
    "project_root = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from datapreparation.Process_1D_data import *\n",
    "from datapreparation.Process_graph_2d_data import *\n",
    "from datapreparation.Process_graph_3d_data import *\n",
    "from datapreparation.Process_mlp_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2920a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_label(data, data_type, device):\n",
    "    data_label_mapping = {\n",
    "        '1d': lambda data: (data[0].to(device), data[1].to(device)),\n",
    "        '2d': lambda data: (data.to(device), data.y.to(device)),\n",
    "        '3d': lambda data: (data.to(device), data.y.to(device)),\n",
    "        '3d_voxels': lambda data: (data[0].to(device), data[1].to(device)),\n",
    "        'mlp': lambda data: (data[0].to(device), data[1].to(device))\n",
    "    }\n",
    "    return data_label_mapping.get(data_type, lambda data: (None, None))(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b90c289",
   "metadata": {},
   "source": [
    "# train model for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ab41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device, data_type):\n",
    "    model.train()\n",
    "    total_loss = total_correct = total = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        inputs, labels = get_data_label(data, data_type, device)\n",
    "        if inputs is None or labels is None:\n",
    "            raise ValueError(f\"Unsupported data type: {data_type}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        if isinstance(criterion, torch.nn.BCEWithLogitsLoss):\n",
    "            labels = labels.float()\n",
    "            labels = labels.unsqueeze(1)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        else:\n",
    "            predicted = torch.max(outputs, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = total_correct / total\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343b6de",
   "metadata": {},
   "source": [
    "# validate model for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a77c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, test_loader, criterion, device, data_type):\n",
    "    model.eval()\n",
    "    total_loss = total_correct = total = TP = FP = TN = FN = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in test_loader:\n",
    "            inputs, labels = get_data_label(data, data_type, device)\n",
    "            if inputs is None or labels is None:\n",
    "                raise ValueError(f\"Unsupported data type: {data_type}\")\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if isinstance(criterion, torch.nn.BCEWithLogitsLoss):\n",
    "                labels = labels.float()\n",
    "                labels = labels.unsqueeze(1)\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            else:\n",
    "                predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            TP += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            TN += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "            FP += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            FN += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    SEN = TP / (TP + FN) if TP + FN else 0\n",
    "    SPE = TN / (TN + FP) if TN + FP else 0\n",
    "    MCC = (TP*TN - FP*FN) / sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)) if (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) else 0\n",
    "    \n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    accuracy = total_correct / total\n",
    "    \n",
    "    return average_loss, accuracy, SEN, SPE, MCC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf13a7",
   "metadata": {},
   "source": [
    "# general training for 1d 2d 3d mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4d8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_general(data, model, optimizer, criterion, batch_size, epoch_num, device, data_type, mode='train', Preprocess=None, scale_path=None):\n",
    "    best_val_accuracy = 0  \n",
    "    best_model_state = None\n",
    "    model_save_dir = f'best_model_{data_type}'\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "        \n",
    "    if data_type == '1d':\n",
    "        smiles_list, labels = unpack_smiles_label(data)\n",
    "        train_loader, test_loader = load_data_1d(smiles_list, labels, batch_size)  \n",
    "    elif data_type == '2d' or data_type == '3d':\n",
    "        torch_graph_data_list = get_torch_graph_data_list(data, mode, Preprocess, scale_path)\n",
    "        train_loader, test_loader = load_graph_data(torch_graph_data_list, batch_size)\n",
    "    elif data_type == '3d_voxels':\n",
    "        train_loader, test_loader = load_3d_voxels_data(data, batch_size)\n",
    "    elif data_type == 'mlp':\n",
    "        fused_features, processed_labels = unpack_fusefeatures_labels(data)\n",
    "        fused_features, processed_labels = standard_data(fused_features, processed_labels, mode, Preprocess, scale_path)\n",
    "        train_loader, test_loader = load_data_mlp(fused_features, processed_labels, batch_size)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported data type: {data_type}\")\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        train_loss, train_accuracy = train_epoch(model, train_loader, optimizer, criterion, device, data_type)\n",
    "        val_loss, val_accuracy, SEN, SPE, MCC = validate_epoch(model, test_loader, criterion, device, data_type)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}/{epoch_num}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, SEN: {SEN:.4f}, SPE: {SPE:.4f}, MCC: {MCC:.4f}')\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            periodic_save_path = os.path.join(model_save_dir, f'model_periodic_epoch_{epoch+1}.pth')\n",
    "            torch.save(model.state_dict(), periodic_save_path)\n",
    "    if best_model_state:\n",
    "        best_model_path = os.path.join(model_save_dir, f'best_model_val_acc_{best_val_accuracy:.4f}.pth')\n",
    "        torch.save(best_model_state, best_model_path)\n",
    "        print(f\"Best model saved: {best_model_path}\")\n",
    "\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd7c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889cb5a6",
   "metadata": {},
   "source": [
    "# 10 fold cv training for 1d 2d 3d mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32537c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_with_10fold_cv(data, model, optimizer, criterion, device, batch_size, epoch_num, data_type, reset=False, n_splits=10, mode='train',Preprocess=None,scale_path=None):\n",
    "    model_save_dir = f'foldcv_models_{data_type}'\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "    val_losses = []\n",
    "\n",
    "    if data_type == '1d':\n",
    "        smiles_list, labels = unpack_smiles_label(data)\n",
    "        split_data = kf.split(smiles_list)\n",
    "    elif data_type == '2d'or data_type == '3d':\n",
    "        torch_graph_data_list = get_torch_graph_data_list(data, mode, Preprocess, scale_path)\n",
    "        split_data = kf.split(torch_graph_data_list)\n",
    "    elif data_type == '3d_voxels':\n",
    "        voxels,labels = get_voxels_labels(data)\n",
    "        split_data = kf.split(voxels)\n",
    "    elif data_type == 'mlp':\n",
    "        fused_features, processed_labels = unpack_fusefeatures_labels(data, mode, Preprocess, scale_path)\n",
    "        fused_features, processed_labels = standard_data(fused_features, processed_labels, mode, Preprocess, scale_path)\n",
    "        split_data = kf.split(fused_features)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(split_data):\n",
    "        print(f'Fold {fold + 1}/{n_splits}')\n",
    "\n",
    "        if reset:\n",
    "            model.apply(reset_weights)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        if data_type == '1d':\n",
    "            train_loader, test_loader = load_data_1d_10fold_cv(smiles_list, labels, train_idx, test_idx, batch_size)\n",
    "        elif data_type == '2d' or data_type == '3d':\n",
    "            train_loader, test_loader = load_graph_data_10fold_cv(torch_graph_data_list, train_idx, test_idx, batch_size)\n",
    "        elif data_type == '3d_voxels': \n",
    "            train_loader, test_loader = load_3d_voxels_data_10fold_cv(voxels, labels, train_idx, test_idx, batch_size)\n",
    "        elif data_type == 'mlp':\n",
    "            train_loader, test_loader = load_data_mlp_10fold_cv(fused_features, processed_labels, train_idx, test_idx, batch_size)\n",
    "\n",
    "        best_val_accuracy = 0\n",
    "        best_model_state = None\n",
    "        best_epoch = -1\n",
    "\n",
    "        for epoch in range(epoch_num):\n",
    "            train_loss, train_accuracy = train_epoch(model, train_loader, optimizer, criterion, device, data_type)\n",
    "            val_loss, val_accuracy, SEN, SPE, MCC = validate_epoch(model, test_loader, criterion, device, data_type)\n",
    "\n",
    "            print(f'Epoch: {epoch+1}/{epoch_num}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, SEN: {SEN:.4f}, SPE: {SPE:.4f}, MCC: {MCC:.4f}')\n",
    "\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_model_state = model.state_dict()\n",
    "                best_epoch = epoch\n",
    "\n",
    "        if best_model_state is not None:\n",
    "            model_save_path = os.path.join(model_save_dir, f'best_model_fold_{fold+1}_epoch_{best_epoch+1}.pth')\n",
    "            torch.save(best_model_state, model_save_path)\n",
    "\n",
    "        val_accuracies.append(best_val_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    avg_val_accuracy = np.mean(val_accuracies)\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    print(f'Average Validation Accuracy: {avg_val_accuracy:.4f}, Average Validation Loss: {avg_val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fa26f",
   "metadata": {},
   "source": [
    "# traini model for machine leaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e50b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def ML_training(X, y, model, scaler_option=None, scale_path=None,pca_components=None,pca_path=None,cv_folds=10):\n",
    "    \n",
    "    if scaler_option == 'standardize':\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        joblib.dump(scaler, scale_path)\n",
    "        \n",
    "    elif scaler_option == 'normalize':\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        joblib.dump(scaler, scale_path)\n",
    "    \n",
    "    if pca_components is not None:\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        X = pca.fit_transform(X)\n",
    "        joblib.dump(pca, pca_path)\n",
    "\n",
    "    total_accuracy = total_sensitivity = total_specificity = total_mcc = 0\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    model_dir = f\"{model_name}_foldcv\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    fold = 0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        model_filename = os.path.join(model_dir, f'model_fold_{fold}.joblib')\n",
    "        joblib.dump(model, model_filename)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "        specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        total_accuracy += accuracy\n",
    "        total_sensitivity += sensitivity\n",
    "        total_specificity += specificity\n",
    "        total_mcc += mcc\n",
    "        \n",
    "        print(f\"Fold {fold}: ACC: {accuracy:.4f}, SEN: {sensitivity:.4f}, SPE: {specificity:.4f}, MCC: {mcc:.4f}\")\n",
    "        fold += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / cv_folds\n",
    "    avg_sensitivity = total_sensitivity / cv_folds\n",
    "    avg_specificity = total_specificity / cv_folds\n",
    "    avg_mcc = total_mcc / cv_folds\n",
    "    \n",
    "    print(f\"Average ACC: {avg_accuracy:.4f}, Average SEN: {avg_sensitivity:.4f}, \"\n",
    "          f\"Average SPE: {avg_specificity:.4f}, Average MCC: {avg_mcc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
