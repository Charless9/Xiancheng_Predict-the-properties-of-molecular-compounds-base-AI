{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e30a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import nbimporter\n",
    "\n",
    "project_root = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from datapreparation.Process_1D_data import *\n",
    "from datapreparation.Process_graph_2d_data import *\n",
    "from datapreparation.Process_graph_3d_data import *\n",
    "from datapreparation.Process_mlp_data import *\n",
    "\n",
    "from models.Model_building import *\n",
    "from augmentation.data_augmentation import *\n",
    "from cv_strategies.train_cv_strategy_123D import *\n",
    "from Extract_features.extract_features_from_dataset import *\n",
    "from testing.offline_test import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f13aae",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999d280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_file = '../dataset/final_canonical_trainset.csv'\n",
    "ori_smiles_df = pd.read_csv(canonical_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b3c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_df_1d = smiles_augmentation(ori_smiles_df, original_multiplier=3, num_variants=3)\n",
    "smiles_df_2d = smiles_augmentation(ori_smiles_df, original_multiplier=3, num_variants=3)\n",
    "smiles_df_3d = smiles_augmentation(ori_smiles_df, original_multiplier=3, num_variants=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0698a67",
   "metadata": {},
   "source": [
    "## set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4270e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list_1d = smiles_df_1d['SMILES'].tolist()\n",
    "tokenizer = create_vocab(smiles_list_1d)\n",
    "stoi = tokenizer['stoi']\n",
    "smiles_list_2d = smiles_df_2d[\"SMILES\"]\n",
    "atom_numbers = get_atom_number(smiles_list_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1454cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = len(stoi)\n",
    "embed_dim = 64\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "num_node_features = 17\n",
    "num_edge_features = 1\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86779c74",
   "metadata": {},
   "source": [
    "## load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607ead1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1d = RNNModel(input_dim, embed_dim, hidden_dim, output_dim=1).to(device)\n",
    "model_2d = EnhancedGCNNnodes(num_node_features, output_dim, dropout_rate=0).to(device)\n",
    "model_3d = GraphNN3D(num_node_features, num_edge_features, output_dim).to(device)\n",
    "model_path_1d = '../Feature_extract/foldcv_models_1d/best_model_fold_9_epoch_1.pth'\n",
    "model_path_2d = '../Feature_extract/best_model_2d/model_periodic_epoch_135.pth'\n",
    "model_path_3d = '../Feature_extract/best_model_3d/model_periodic_epoch_50.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b4744",
   "metadata": {},
   "source": [
    "## feature  extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fe5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocess_2d = 'standardize'          # None   'standardize'   'normalize'\n",
    "scale_path_2d = '../Feature_extract/standardize_scale_cv_2d.pkl'          # \n",
    "Preprocess_3d = 'standardize'          # None   'standardize'   'normalize'\n",
    "scale_path_3d = '../Feature_extract/standardize_scale_cv_3d.pkl '         #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3982a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get graph_data: 100%|█████████████████████████████████████████████████████████████| 7446/7446 [00:08<00:00, 893.35it/s]\n",
      "get graph_data: 100%|██████████████████████████████████████████████████████████████| 7446/7446 [18:52<00:00,  6.57it/s]\n"
     ]
    }
   ],
   "source": [
    "all_features_1d, all_labels_1d = integrated_feature_extraction('1d', model_1d, model_path_1d, smiles_df_1d, device, 1, tokenizer=tokenizer,atom_numbers=None, \\\n",
    "                                                               mode='test',Preprocess=None,scale_path=None)\n",
    "all_features_2d, all_labels_2d = integrated_feature_extraction('2d', model_2d, model_path_2d, smiles_df_2d, device, 1, tokenizer=None,atom_numbers=atom_numbers, \\\n",
    "                                                               mode='test',Preprocess=Preprocess_2d,scale_path=scale_path_2d)\n",
    "all_features_3d, all_labels_3d = integrated_feature_extraction('3d', model_3d, model_path_3d, smiles_df_3d, device, 1, tokenizer=None,atom_numbers=atom_numbers, \\\n",
    "                                                               mode='test',Preprocess=Preprocess_3d,scale_path=scale_path_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27618d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7446, 128) (7446,)\n",
      "(7446, 64) (7446,)\n",
      "(7446, 129) (7446,)\n"
     ]
    }
   ],
   "source": [
    "print(all_features_1d.shape, all_labels_1d.shape)\n",
    "print(all_features_2d.shape, all_labels_2d.shape)\n",
    "print(all_features_3d.shape, all_labels_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec035c3b",
   "metadata": {},
   "source": [
    "## fuse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1552b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_features = np.concatenate([all_features_1d, all_features_2d, all_features_3d], axis=1)\n",
    "fused_labels = all_labels_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b49442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7446, 321) (7446,)\n"
     ]
    }
   ],
   "source": [
    "print(fused_features.shape, fused_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5761c5e",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89f498",
   "metadata": {},
   "source": [
    "## Training_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793cc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94521038",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y= fused_features, fused_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e999914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_option = None            # None   'standardize'   'normalize'\n",
    "scale_path_ml = None           # None 'standardize_scaler.pkl'   'normalize_scaler.pkl'\n",
    "pca_components = None         # 100 50 ...\n",
    "pca_path = None              # None  'pca.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adf73c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: ACC: 0.6926, SEN: 0.6824, SPE: 0.7033, MCC: 0.3856\n",
      "Fold 1: ACC: 0.6966, SEN: 0.7218, SPE: 0.6703, MCC: 0.3927\n",
      "Fold 2: ACC: 0.6872, SEN: 0.6955, SPE: 0.6786, MCC: 0.3741\n",
      "Fold 3: ACC: 0.7060, SEN: 0.7139, SPE: 0.6978, MCC: 0.4117\n",
      "Fold 4: ACC: 0.7020, SEN: 0.7060, SPE: 0.6978, MCC: 0.4038\n",
      "Fold 5: ACC: 0.7047, SEN: 0.7139, SPE: 0.6951, MCC: 0.4090\n",
      "Fold 6: ACC: 0.7030, SEN: 0.7270, SPE: 0.6777, MCC: 0.4053\n",
      "Fold 7: ACC: 0.7083, SEN: 0.7244, SPE: 0.6915, MCC: 0.4161\n",
      "Fold 8: ACC: 0.6855, SEN: 0.6903, SPE: 0.6804, MCC: 0.3707\n",
      "Fold 9: ACC: 0.6922, SEN: 0.7087, SPE: 0.6749, MCC: 0.3838\n",
      "Average ACC: 0.6978, Average SEN: 0.7084, Average SPE: 0.6867, Average MCC: 0.3953\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', C=1)\n",
    "ML_training(X, y, svm_model, scaler_option=scaler_option, scale_path=scale_path_ml,pca_components=pca_components,pca_path=pca_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98bc71c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: ACC: 0.9114, SEN: 0.9160, SPE: 0.9066, MCC: 0.8227\n",
      "Fold 1: ACC: 0.9141, SEN: 0.9318, SPE: 0.8956, MCC: 0.8284\n",
      "Fold 2: ACC: 0.9060, SEN: 0.9055, SPE: 0.9066, MCC: 0.8120\n",
      "Fold 3: ACC: 0.9235, SEN: 0.9318, SPE: 0.9148, MCC: 0.8469\n",
      "Fold 4: ACC: 0.9342, SEN: 0.9475, SPE: 0.9203, MCC: 0.8686\n",
      "Fold 5: ACC: 0.9450, SEN: 0.9528, SPE: 0.9368, MCC: 0.8899\n",
      "Fold 6: ACC: 0.9341, SEN: 0.9318, SPE: 0.9366, MCC: 0.8683\n",
      "Fold 7: ACC: 0.9234, SEN: 0.9528, SPE: 0.8926, MCC: 0.8478\n",
      "Fold 8: ACC: 0.9140, SEN: 0.9160, SPE: 0.9118, MCC: 0.8279\n",
      "Fold 9: ACC: 0.9140, SEN: 0.9265, SPE: 0.9008, MCC: 0.8280\n",
      "Average ACC: 0.9220, Average SEN: 0.9312, Average SPE: 0.9123, Average MCC: 0.8440\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "ML_training(X, y, rf_model, scaler_option=scaler_option, scale_path=scale_path_ml,pca_components=pca_components,pca_path=pca_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85dce6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: ACC: 0.8282, SEN: 0.8425, SPE: 0.8132, MCC: 0.6562\n",
      "Fold 1: ACC: 0.8564, SEN: 0.8740, SPE: 0.8379, MCC: 0.7127\n",
      "Fold 2: ACC: 0.8403, SEN: 0.8084, SPE: 0.8736, MCC: 0.6827\n",
      "Fold 3: ACC: 0.8604, SEN: 0.8714, SPE: 0.8489, MCC: 0.7207\n",
      "Fold 4: ACC: 0.8685, SEN: 0.8898, SPE: 0.8462, MCC: 0.7371\n",
      "Fold 5: ACC: 0.8523, SEN: 0.8609, SPE: 0.8434, MCC: 0.7045\n",
      "Fold 6: ACC: 0.8723, SEN: 0.8478, SPE: 0.8981, MCC: 0.7460\n",
      "Fold 7: ACC: 0.8589, SEN: 0.8898, SPE: 0.8264, MCC: 0.7183\n",
      "Fold 8: ACC: 0.8387, SEN: 0.8268, SPE: 0.8512, MCC: 0.6778\n",
      "Fold 9: ACC: 0.8481, SEN: 0.8688, SPE: 0.8264, MCC: 0.6962\n",
      "Average ACC: 0.8524, Average SEN: 0.8580, Average SPE: 0.8465, Average MCC: 0.7052\n"
     ]
    }
   ],
   "source": [
    "gbt_model = GradientBoostingClassifier(n_estimators=100)\n",
    "ML_training(X, y, gbt_model, scaler_option=scaler_option, scale_path=scale_path_ml,pca_components=pca_components,pca_path=pca_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e9979f",
   "metadata": {},
   "source": [
    "# offline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef72bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "offlinetest_file = '../dataset/canonical_offlinetestset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0303cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_df_test = pd.read_csv(offlinetest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c6b3e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get graph_data: 100%|███████████████████████████████████████████████████████████████| 205/205 [00:00<00:00, 791.30it/s]\n",
      "get graph_data: 100%|████████████████████████████████████████████████████████████████| 205/205 [00:18<00:00, 11.28it/s]\n"
     ]
    }
   ],
   "source": [
    "all_features_1d_test, all_labels_1d_test = integrated_feature_extraction('1d', model_1d, model_path_1d, smiles_df_test, device, 1, tokenizer=tokenizer, atom_numbers=atom_numbers, \\\n",
    "                                                                         mode='test',Preprocess=None,scale_path=None)\n",
    "all_features_2d_test, all_labels_2d_test = integrated_feature_extraction('2d', model_2d, model_path_2d, smiles_df_test, device, 1, tokenizer=tokenizer, atom_numbers=atom_numbers, \\\n",
    "                                                                         mode='test',Preprocess=Preprocess_2d,scale_path=scale_path_2d)\n",
    "all_features_3d_test, all_labels_3d_test = integrated_feature_extraction('3d', model_3d, model_path_3d, smiles_df_test, device, 1, tokenizer=tokenizer, atom_numbers=atom_numbers, \\\n",
    "                                                                         mode='test',Preprocess=Preprocess_3d,scale_path=scale_path_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01971bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_features_test = np.concatenate([all_features_1d_test, all_features_2d_test, all_features_3d_test], axis=1)\n",
    "fused_labels_test = all_labels_2d_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541302c",
   "metadata": {},
   "source": [
    "## ML test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec9eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir_svm = 'SVC_foldcv/'\n",
    "model_save_dir_RF = 'RandomForestClassifier_foldcv/'\n",
    "model_save_dir_GB = 'GradientBoostingClassifier_foldcv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ee71f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model_fold_0.joblib: ACC: 0.6537, SEN: 0.8617, SPE: 0.4775, MCC: 0.3617\n",
      "Model model_fold_1.joblib: ACC: 0.6732, SEN: 0.9255, SPE: 0.4595, MCC: 0.4259\n",
      "Model model_fold_2.joblib: ACC: 0.6683, SEN: 0.9043, SPE: 0.4685, MCC: 0.4062\n",
      "Model model_fold_3.joblib: ACC: 0.6439, SEN: 0.8936, SPE: 0.4324, MCC: 0.3607\n",
      "Model model_fold_4.joblib: ACC: 0.6585, SEN: 0.8936, SPE: 0.4595, MCC: 0.3848\n",
      "Model model_fold_5.joblib: ACC: 0.6537, SEN: 0.9043, SPE: 0.4414, MCC: 0.3824\n",
      "Model model_fold_6.joblib: ACC: 0.6341, SEN: 0.8936, SPE: 0.4144, MCC: 0.3445\n",
      "Model model_fold_7.joblib: ACC: 0.6585, SEN: 0.9043, SPE: 0.4505, MCC: 0.3904\n",
      "Model model_fold_8.joblib: ACC: 0.6439, SEN: 0.9043, SPE: 0.4234, MCC: 0.3664\n",
      "Model model_fold_9.joblib: ACC: 0.6537, SEN: 0.8723, SPE: 0.4685, MCC: 0.3665\n",
      "Average ACC: 0.6541, Average SEN: 0.8957, Average SPE: 0.4495, Average MCC: 0.3790\n"
     ]
    }
   ],
   "source": [
    "ML_testing(fused_features_test, fused_labels_test, model_save_dir_svm, scale_path=scale_path_ml, pca_path=pca_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54b8836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model_fold_0.joblib: ACC: 0.7707, SEN: 0.9255, SPE: 0.6396, MCC: 0.5800\n",
      "Model model_fold_1.joblib: ACC: 0.7366, SEN: 0.8830, SPE: 0.6126, MCC: 0.5074\n",
      "Model model_fold_2.joblib: ACC: 0.7463, SEN: 0.9043, SPE: 0.6126, MCC: 0.5318\n",
      "Model model_fold_3.joblib: ACC: 0.7415, SEN: 0.9149, SPE: 0.5946, MCC: 0.5286\n",
      "Model model_fold_4.joblib: ACC: 0.7415, SEN: 0.8936, SPE: 0.6126, MCC: 0.5195\n",
      "Model model_fold_5.joblib: ACC: 0.7561, SEN: 0.9149, SPE: 0.6216, MCC: 0.5520\n",
      "Model model_fold_6.joblib: ACC: 0.7268, SEN: 0.8723, SPE: 0.6036, MCC: 0.4873\n",
      "Model model_fold_7.joblib: ACC: 0.7659, SEN: 0.9255, SPE: 0.6306, MCC: 0.5722\n",
      "Model model_fold_8.joblib: ACC: 0.7512, SEN: 0.8936, SPE: 0.6306, MCC: 0.5355\n",
      "Model model_fold_9.joblib: ACC: 0.7561, SEN: 0.9362, SPE: 0.6036, MCC: 0.5617\n",
      "Average ACC: 0.7493, Average SEN: 0.9064, Average SPE: 0.6162, Average MCC: 0.5376\n"
     ]
    }
   ],
   "source": [
    "ML_testing(fused_features_test, fused_labels_test, model_save_dir_RF, scale_path=scale_path_ml, pca_path=pca_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e55d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model_fold_0.joblib: ACC: 0.7610, SEN: 0.9149, SPE: 0.6306, MCC: 0.5599\n",
      "Model model_fold_1.joblib: ACC: 0.7512, SEN: 0.8936, SPE: 0.6306, MCC: 0.5355\n",
      "Model model_fold_2.joblib: ACC: 0.7366, SEN: 0.9043, SPE: 0.5946, MCC: 0.5161\n",
      "Model model_fold_3.joblib: ACC: 0.7366, SEN: 0.8936, SPE: 0.6036, MCC: 0.5116\n",
      "Model model_fold_4.joblib: ACC: 0.7415, SEN: 0.8936, SPE: 0.6126, MCC: 0.5195\n",
      "Model model_fold_5.joblib: ACC: 0.7415, SEN: 0.8723, SPE: 0.6306, MCC: 0.5116\n",
      "Model model_fold_6.joblib: ACC: 0.7463, SEN: 0.9043, SPE: 0.6126, MCC: 0.5318\n",
      "Model model_fold_7.joblib: ACC: 0.7561, SEN: 0.8936, SPE: 0.6396, MCC: 0.5435\n",
      "Model model_fold_8.joblib: ACC: 0.7512, SEN: 0.8830, SPE: 0.6396, MCC: 0.5316\n",
      "Model model_fold_9.joblib: ACC: 0.7366, SEN: 0.8936, SPE: 0.6036, MCC: 0.5116\n",
      "Average ACC: 0.7459, Average SEN: 0.8947, Average SPE: 0.6198, Average MCC: 0.5273\n"
     ]
    }
   ],
   "source": [
    "ML_testing(fused_features_test, fused_labels_test, model_save_dir_GB, scale_path=scale_path_ml, pca_path=pca_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4b78e",
   "metadata": {},
   "source": [
    "# Training_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_dim = fused_features_mlp.shape[1]\n",
    "output_dim = 1\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#output_dim = 2\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 4\n",
    "epoch_num = 20\n",
    "scale_path_mlp ='standardize_scale_mlp.pkl'             # None    'standardize_scale_mlp.pkl'  'normalize_scale_mlp.pkl'\n",
    "scale_path_cv_mlp = 'standardize_scale_cv_mlp.pkl'    # None    'standardize_scale_cv_mlp.pkl'\n",
    "Preprocessmlp = 'standardize'                       # None   'standardize'   'normalize'\n",
    "Preprocesscv_mlp = 'standardize'                    # None   'standardize'   'normalize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16056aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_data = pack_fusefeatures_labels(fused_features,fused_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp_model_general = MLP(input_size=fused_dim, hidden_size=100, output_dim=output_dim).to(device)\n",
    "mlp_model_general = ComplexMLP(fused_dim, [128, 64, 32], 1, 0)\n",
    "optimizer_general = optim.Adam(mlp_model_general.parameters(),lr=0.001)\n",
    "training_general(mlp_data, mlp_model_general, optimizer_general, criterion, batch_size, epoch_num, device, 'mlp', \\\n",
    "                 mode='train', Preprocess=Preprocessmlp, scale_path=scale_path_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230656c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp_model_cv = MLP(input_size=fused_dim, hidden_size=100, output_dim=output_dim).to(device)\n",
    "mlp_model_cv = ComplexMLP(fused_dim, [256,128,64], 1, 0)\n",
    "optimizer_cv = optim.Adam(mlp_model_cv.parameters())\n",
    "training_with_10fold_cv(mlp_data, mlp_model_cv, optimizer_cv, criterion, device, batch_size, 10, 'mlp', \\\n",
    "                        reset=False, n_splits=10, mode='train',Preprocess=Preprocesscv_mlp,scale_path=scale_path_cv_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fc22f",
   "metadata": {},
   "source": [
    "## MLP test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_features_mlp_test, labels_mlp_test = standard_data(fused_features_test, fused_labels_test, 'test', \\\n",
    "                                                         Preprocess=Preprocessmlp, scale_path=scale_path_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_test_data_loader = load_data_for_offline_test(fused_features_mlp_test, labels_mlp_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_features_mlp_cv_test, labels_mlp_cv_test = standard_data(fused_features_test, fused_labels_test, 'test', \\\n",
    "                                                         Preprocess=Preprocesscv_mlp, scale_path=scale_path_cv_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_cv_test_data_loader = load_data_for_offline_test(fused_features_mlp_cv_test, labels_mlp_cv_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_mlp  foldcv_models_mlp\n",
    "model_save_dir1 = 'best_model_mlp/'\n",
    "model_save_dir2 = 'foldcv_models_mlp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b907d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_file in os.listdir(model_save_dir1):\n",
    "    model_path = os.path.join(model_save_dir1, model_file)\n",
    "    ACC, SEN, SPE, MCC = offline_test_model(mlp_model_general, criterion, model_path, mlp_test_data_loader, device, 'mlp')\n",
    "    print(f\"Model: {model_file}, ACC: {ACC:.4f}, SEN: {SEN:.4f}, SPE: {SPE:.4f}, MCC: {MCC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcdcf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_file in os.listdir(model_save_dir2):\n",
    "    model_path = os.path.join(model_save_dir2, model_file)\n",
    "    ACC, SEN, SPE, MCC = offline_test_model(mlp_model_cv, criterion, model_path, mlp_cv_test_data_loader, device, 'mlp')\n",
    "    print(f\"Model: {model_file}, ACC: {ACC:.4f}, SEN: {SEN:.4f}, SPE: {SPE:.4f}, MCC: {MCC:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a974c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
